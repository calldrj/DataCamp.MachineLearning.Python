{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomly Sample Hyperparameters\n",
    "To undertake a random search, we firstly need to undertake a random sampling of our hyperparameter space.\n",
    "\n",
    "In this exercise, you will firstly create some lists of hyperparameters that can be zipped up to a list of lists. Then you will randomly sample hyperparameter combinations preparation for running a random search.\n",
    "\n",
    "You will use just the hyperparameters learning_rate and min_samples_leaf of the GBM algorithm to keep the example illustrative and not overly complicated.\n",
    "\n",
    "### Instructions\n",
    "Create a list of 200 values for the learning_rate hyperparameter between 0.01 and 1.5 and assign to the list learn_rate_list.   \n",
    "Create a list of values between 10 and 40 inclusive for the hyperparameter min_samples_leaf and assign to the list min_samples_list.  \n",
    "Combine these lists into a list of lists to sample from.   \n",
    "Randomly sample 250 models from these hyperparameter combinations and print the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of values for the learning_rate hyperparameter\n",
    "learn_rate_list = list(np.linspace(.01, 1.5, 200))\n",
    "\n",
    "# Create a list of values for the min_samples_leaf hyperparameter\n",
    "min_samples_list = list(np.arange(10, 41))\n",
    "\n",
    "# Combination list\n",
    "combinations_list = [list(x) for x in product(learn_rate_list, min_samples_list)]\n",
    "\n",
    "# Sample hyperparameter combinations for a random search.\n",
    "random_combinations_index = np.random.choice(range(0, len(combinations_list)), 250, replace=False)\n",
    "combinations_random_chosen = [combinations_list[x] for x in random_combinations_index]\n",
    "\n",
    "# Print the result\n",
    "print(combinations_random_chosen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomly Search with Random Forest\n",
    "To solidify your knowledge of random sampling, let's try a similar exercise but using different hyperparameters and a different algorithm.\n",
    "\n",
    "As before, create some lists of hyperparameters that can be zipped up to a list of lists. You will use the hyperparameters criterion, max_depth and max_features of the random forest algorithm. Then you will randomly sample hyperparameter combinations in preparation for running a random search.\n",
    "\n",
    "You will use a slightly different package for sampling in this task, random.sample().\n",
    "\n",
    "### Instructions\n",
    "Create lists of the values 'gini' and 'entropy' for criterion & \"auto\", \"sqrt\", \"log2\", None for max_features.  \n",
    "Create a list of values between 3 and 55 inclusive for the hyperparameter max_depth and assign to the list  max_depth_list. Remember that range(N,M) will create a list from N to M-1.  \n",
    "Combine these lists into a list of lists to sample from using product().  \n",
    "Randomly sample 150 models from the combined list and print the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists for criterion and max_features\n",
    "criterion_list = ['gini', 'entropy']\n",
    "max_feature_list = ['auto', 'sqrt', 'log2', None]\n",
    "\n",
    "# Create a list of values for the max_depth hyperparameter\n",
    "max_depth_list = list(range(3,56))\n",
    "\n",
    "# Combination list\n",
    "combinations_list = [list(x) for x in product(criterion_list, max_feature_list, max_depth_list)]\n",
    "\n",
    "# Sample hyperparameter combinations for a random search\n",
    "combinations_random_chosen = random.sample(combinations_list, 150)\n",
    "\n",
    "# Print the result\n",
    "print(combinations_random_chosen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing a Random Search\n",
    "Visualizing the search space of random search allows you to easily see the coverage of this technique and therefore allows you to see the effect of your sampling on the search space.\n",
    "\n",
    "In this exercise you will use several different samples of hyperparameter combinations and produce visualizations of the search space.\n",
    "\n",
    "The function sample_and_visualize_hyperparameters() takes a single argument (number of combinations to sample) and then randomly samples hyperparameter combinations, just like you did in the last exercise! The function will then visualize the combinations.\n",
    "\n",
    "If you want to see the function definition, you can use Python's handy inspect library, like so:\n",
    "\n",
    "print(inspect.getsource(sample_and_visualize_hyperparameters))\n",
    "\n",
    "### Instructions\n",
    "Confirm how many possible hyperparameter combinations there are in combinations_list by assigning to the variable number_combs and print this out.  \n",
    "Sample and visualize 50, 500 and 1500 combinations. You will use a loop for succinctness. What do you notice about the visualization?  \n",
    "Now sample and visualize the entire set of combinations. You have already made a variable to assist with this. What does this look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm how many hyperparameter combinations & print\n",
    "number_combs = len(combinations_list)\n",
    "print(number_combs)\n",
    "\n",
    "# Sample and visualise specified combinations\n",
    "for x in [50, 500, 1500]:\n",
    "    sample_and_visualize_hyperparameters(x)\n",
    "    \n",
    "# Sample all the hyperparameter combinations & visualise\n",
    "sample_and_visualize_hyperparameters(number_combs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The RandomizedSearchCV Object\n",
    "Just like the GridSearchCV library from Scikit Learn, RandomizedSearchCV provides many useful features to assist with efficiently undertaking a random search. You're going to create a RandomizedSearchCV object, making the small adjustment needed from the GridSearchCV object.\n",
    "\n",
    "The desired options are:\n",
    "\n",
    "A default Gradient Boosting Classifier Estimator   \n",
    "5-fold cross validation   \n",
    "Use accuracy to score the models  \n",
    "Use 4 cores for processing in parallel  \n",
    "Ensure you refit the best model and return training scores  \n",
    "Randomly sample 10 models  \n",
    "The hyperparameter grid should be for learning_rate (150 values between 0.1 and 2) and min_samples_leaf (all values between and including 20 and 64).  \n",
    "\n",
    "You will have available X_train & y_train datasets.\n",
    "\n",
    "### Instructions\n",
    "Create a parameter grid as specified in the context above.  \n",
    "Create a RandomizedSearchCV object as outlined in the context above.  \n",
    "Fit the RandomizedSearchCV object to the training data.  \n",
    "Print the values chosen by the modeling process for both hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid\n",
    "param_grid = {'learning_rate': np.linspace(.1,2,150), 'min_samples_leaf': list(range(20,65))} \n",
    "\n",
    "# Create a random search object\n",
    "random_GBM_class = RandomizedSearchCV(\n",
    "    estimator = GradientBoostingClassifier(),\n",
    "    param_distributions = param_grid,\n",
    "    n_iter = 10,\n",
    "    scoring='accuracy', n_jobs=4, cv=5, refit=True, return_train_score=True)\n",
    "\n",
    "# Fit to the training data\n",
    "random_GBM_class.fit(X_train, y_train)\n",
    "\n",
    "# Print the values used for both hyperparameters\n",
    "print(random_GBM_class.cv_results_['param_learning_rate'])\n",
    "print(random_GBM_class.cv_results_['param_min_samples_leaf'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomSearchCV in Scikit Learn\n",
    "Let's practice building a RandomizedSearchCV object using Scikit Learn.\n",
    "\n",
    "The hyperparameter grid should be for max_depth (all values between and including 5 and 25) and max_features ('auto' and 'sqrt').\n",
    "\n",
    "The desired options for the RandomizedSearchCV object are:\n",
    "\n",
    "A RandomForestClassifier Estimator with n_estimators of 80.  \n",
    "3-fold cross validation (cv)  \n",
    "Use roc_auc to score the models  \n",
    "Use 4 cores for processing in parallel (n_jobs)  \n",
    "Ensure you refit the best model and return training scores  \n",
    "Only sample 5 models for efficiency (n_iter)  \n",
    "X_train & y_train datasets are loaded for you.  \n",
    "\n",
    "Remember, to extract the chosen hyperparameters these are found in cv_results_ with a column per hyperparameter. For example, the column for the hyperparameter criterion would be param_criterion.\n",
    "\n",
    "### Instructions\n",
    "Create a hyperparameter grid as specified in the context above.   \n",
    "Create a RandomizedSearchCV object as outlined in the context above.   \n",
    "Fit the RandomizedSearchCV object to the training data.  \n",
    "Index into the cv_results_ object to print the values chosen by the modeling process for both hyperparameters (max_depth and max_features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid\n",
    "param_grid = {'max_depth': list(range(5,26)), 'max_features': ['auto' , 'sqrt']} \n",
    "\n",
    "# Create a random search object\n",
    "random_rf_class = RandomizedSearchCV(\n",
    "    estimator = RandomForestClassifier(n_estimators=80),\n",
    "    param_distributions=param_grid, n_iter=5,\n",
    "    scoring='roc_auc', n_jobs=4, cv=3, refit=True, return_train_score=True )\n",
    "\n",
    "# Fit to the training data\n",
    "random_rf_class.fit(X_train, y_train)\n",
    "\n",
    "# Print the values used for both hyperparameters\n",
    "print(random_rf_class.cv_results_['param_max_depth'])\n",
    "print(random_rf_class.cv_results_['param_max_features'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid and Random Search Side by Side\n",
    "Visualizing the search space of random and grid search together allows you to easily see the coverage that each technique has and therefore brings to life their specific advantages and disadvantages.\n",
    "\n",
    "In this exercise, you will sample hyperparameter combinations in a grid search way as well as a random search way, then plot these to see the difference.\n",
    "\n",
    "You will have available:\n",
    "\n",
    "combinations_list which is a list of combinations of learn_rate and min_samples_leaf for this algorithm  \n",
    "The function visualize_search() which will make your hyperparameter combinations into X and Y coordinates and plot both grid and random search combinations on the same graph.   \n",
    "It takes as input two lists of hyperparameter combinations.\n",
    "### Instructions\n",
    "Sample (by slicing) 300 hyperparameter combinations for a grid search from combinations_list into two lists and print the result.   \n",
    "Let's randomly sample too. Create a list of every index in combinations_list to sample from using range()   \n",
    "Use np.random.choice() to sample 300 combinations. The first two arguments are a list to sample from and the number of samples.   \n",
    "Use the provided visualize_search() function to visualize the two sampling methodologies. The first argument is your grid combinations, the second argument is the random combinations you created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample grid coordinates\n",
    "grid_combinations_chosen = combinations_list[0:300]\n",
    "\n",
    "# Create a list of sample indexes\n",
    "sample_indexes = list(range(0,len(combinations_list)))\n",
    "\n",
    "# Randomly sample 300 indexes\n",
    "random_indexes = np.random.choice(sample_indexes, 300, replace=False)\n",
    "\n",
    "# Use indexes to create random sample\n",
    "random_combinations_chosen = [combinations_list[index] for index in random_indexes]\n",
    "\n",
    "# Call the function to produce the visualization\n",
    "visualize_search(grid_combinations_chosen, random_combinations_chosen)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
