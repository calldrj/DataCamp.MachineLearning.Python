{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducing the dataset\n",
    "As mentioned in the video, you'll deal with stock market prices that fluctuate over time. In this exercise you've got historical prices from two tech companies (Ebay and Yahoo) in the DataFrame prices.    \n",
    "You'll visualize the raw data for the two companies, then generate a scatter plot showing how the values for each company compare with one another.    \n",
    "Finally, you'll add in a \"time\" dimension to your scatter plot so you can see how this relationship changes over time.\n",
    "\n",
    "The data has been loaded into a DataFrame called prices.   \n",
    "\n",
    "### Instructions\n",
    "Plot the data in prices. Pay attention to any irregularities you notice.   \n",
    "Generate a scatter plot with the values of Ebay on the x-axis, and Yahoo on the y-axis. Look up the symbols for both companies from the column names of the DataFrame.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the raw values over time\n",
    "prices.plot()\n",
    "plt.show()\n",
    "\n",
    "# Scatterplot with one company per axis\n",
    "plt.clf()\n",
    "prices.plot.scatter('EBAY', 'YHOO')\n",
    "plt.show()\n",
    "\n",
    "# Scatterplot with color relating to time\n",
    "plt.clf()\n",
    "prices.plot.scatter('EBAY', 'YHOO', c=prices.index, \n",
    "                    cmap=plt.cm.viridis, colorbar=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing messy data\n",
    "Let's take a look at a new dataset - this one is a bit less-clean than what you've seen before.    \n",
    "As always, you'll first start by visualizing the raw data. Take a close look and try to find datapoints that could be problematic for fitting models.      \n",
    "The data has been loaded into a DataFrame called prices.\n",
    "### Instructions\n",
    "Visualize the time series data using Pandas.     \n",
    "Calculate the number of missing values in each time series. Note any irregularities that you can see. What do you think they are?   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the dataset\n",
    "prices.plot(legend=False)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Count the missing values of each time series\n",
    "missing_values = prices.isna().sum()\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing missing values\n",
    "When you have missing data points, how can you fill them in?     \n",
    "In this exercise, you'll practice using different interpolation methods to fill in some missing values, visualizing the result each time. But first, you will create the function (interpolate_and_plot()) you'll use to interpolate missing data points and plot them.   \n",
    "A single time series has been loaded into a DataFrame called prices.\n",
    "\n",
    "### Instructions\n",
    "Create a boolean mask for missing values and interpolate the missing values using the interpolation argument of the function.    \n",
    "Interpolate using the latest non-missing value and plot the results.    \n",
    "Recall that interpolate_and_plot's second input is a string specifying the kind of interpolation to use.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function we'll use to interpolate and plot\n",
    "def interpolate_and_plot(prices, interpolation):\n",
    "\n",
    "    # Create a boolean mask for missing values\n",
    "    missing_values = prices.isna()\n",
    "\n",
    "    # Interpolate the missing values\n",
    "    prices_interp = prices.interpolate(interpolation)\n",
    "\n",
    "    # Plot the results, highlighting the interpolated values in black\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    prices_interp.plot(color='k', alpha=.6, ax=ax, legend=False)\n",
    "    \n",
    "    # Now plot the interpolated values on top in red\n",
    "    prices_interp[missing_values].plot(ax=ax, color='r', lw=3, legend=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate using the latest non-missing value\n",
    "interpolation_type = 'zero'\n",
    "interpolate_and_plot(prices, interpolation_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate linearly\n",
    "interpolation_type = 'linear'\n",
    "interpolate_and_plot(prices, interpolation_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate with a quadratic function\n",
    "interpolation_type = 'quadratic'\n",
    "interpolate_and_plot(prices, interpolation_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming raw data\n",
    "In the last chapter, you calculated the rolling mean. In this exercise, you will define a function that calculates the percent change of the latest data point from the mean of a window of previous data points. This function will help you calculate the percent change over a rolling window.    \n",
    "This is a more stable kind of time series that is often useful in machine learning.\n",
    "\n",
    "### Instructions\n",
    "Define a percent_change function that takes an input time series and does the following:    \n",
    "Extract all but the last value of the input series (assigned to previous_values) and the only the last value of the timeseries ( assigned to last_value)    \n",
    "Calculate the percentage difference between the last value and the mean of earlier values.   \n",
    "Using a rolling window of 20, apply this function to prices, and visualize it using the given code.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your custom function\n",
    "def percent_change(series):\n",
    "    # Collect all *but* the last value of this window, then the final value\n",
    "    previous_values = series[:-1]\n",
    "    last_value = series[-1]\n",
    "\n",
    "    # Calculate the % difference between the last value and the mean of earlier values\n",
    "    percent_change = (last_value - np.mean(previous_values)) / np.mean(previous_values)\n",
    "    return percent_change\n",
    "\n",
    "# Apply your custom function and plot\n",
    "prices_perc = prices.rolling(20).aggregate(percent_change)\n",
    "prices_perc.loc[\"2014\":\"2015\"].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling outliers\n",
    "In this exercise, you'll handle outliers - data points that are so different from the rest of your data, that you treat them differently from other \"normal-looking\" data points. You'll use the output from the previous exercise (percent change over time) to detect the outliers. First you will write a function that replaces outlier data points with the median value from the entire time series.   \n",
    "### Instructions\n",
    "Define a function that takes an input series and does the following:     \n",
    "Calculates the absolute value of each datapoint's distance from the series mean, then creates a boolean mask for datapoints that are three times the standard deviation from the mean.    \n",
    "Use this boolean mask to replace the outliers with the median of the entire series.    \n",
    "Apply this function to your data and visualize the results using the given code.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_outliers(series):\n",
    "    # Calculate the absolute difference of each timepoint from the series mean\n",
    "    absolute_differences_from_mean = np.abs(series - np.mean(series))\n",
    "    \n",
    "    # Calculate a mask for the differences that are > 3 standard deviations from zero\n",
    "    this_mask = absolute_differences_from_mean > (np.std(series) * 3)\n",
    "    \n",
    "    # Replace these values with the median accross the data\n",
    "    series[this_mask] = np.nanmedian(series)\n",
    "    return series\n",
    "    \n",
    "# Apply your preprocessing function to the timeseries and plot the results\n",
    "prices_perc = prices_perc.aggregate(replace_outliers)\n",
    "prices_perc.loc[\"2014\":\"2015\"].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Engineering multiple rolling features at once\n",
    "Now that you've practiced some simple feature engineering, let's move on to something more complex. You'll calculate a collection of features for your time series data and visualize what they look like over time. This process resembles how many other time series models operate.\n",
    "### Instructions\n",
    "Define a list consisting of four features you will calculate: the minimum, maximum, mean, and standard deviation (in that order).    \n",
    "Using the rolling window (prices_perc_rolling) we defined for you, calculate the features from features_to_calculate.    \n",
    "Plot the results over time, along with the original time series using the given code.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a rolling window with Pandas, excluding the right-most datapoint of the window\n",
    "prices_perc_rolling = prices_perc.rolling(20, min_periods=5, closed='right')\n",
    "\n",
    "# Define the features you'll calculate for each window\n",
    "features_to_calculate = [np.min, np.max, np.mean, np.std]\n",
    "\n",
    "# Calculate these features for your rolling window object\n",
    "features = prices_perc_rolling.aggregate(features_to_calculate)\n",
    "\n",
    "# Plot the results\n",
    "ax = features.loc[:\"2011-01\"].plot()\n",
    "prices_perc.loc[:\"2011-01\"].plot(ax=ax, color='k', alpha=.2, lw=3)\n",
    "ax.legend(loc=(1.01, .6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentiles and partial functions\n",
    "In this exercise, you'll practice how to pre-choose arguments of a function so that you can pre-configure how it runs. You'll use this to calculate several percentiles of your data using the same percentile() function in numpy.\n",
    "\n",
    "### Instructions\n",
    "Import partial from functools.   \n",
    "Use the partial() function to create several feature generators that calculate percentiles of your data using a list comprehension.   \n",
    "Using the rolling window (prices_perc_rolling) we defined for you, calculate the quantiles using percentile_functions.   \n",
    "Visualize the results using the code given to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import partial from functools\n",
    "from functools import partial\n",
    "percentiles = [1, 10, 25, 50, 75, 90, 99]\n",
    "\n",
    "# Use a list comprehension to create a partial function for each quantile\n",
    "percentile_functions = [partial(np.percentile, q=percentile) for percentile in percentiles]\n",
    "\n",
    "# Calculate each of these quantiles on the data using a rolling window\n",
    "prices_perc_rolling = prices_perc.rolling(20, min_periods=5, closed='right')\n",
    "features_percentiles = prices_perc_rolling.aggregate(percentile_functions)\n",
    "\n",
    "# Plot a subset of the result\n",
    "ax = features_percentiles.loc[:\"2011-01\"].plot(cmap=plt.cm.viridis)\n",
    "ax.legend(percentiles, loc=(1.01, .5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using \"date\" information\n",
    "It's easy to think of timestamps as pure numbers, but don't forget they generally correspond to things that happen in the real world. That means there's often extra information encoded in the data such as \"is it a weekday?\" or \"is it a holiday?\". This information is often useful in predicting timeseries data.    \n",
    "In this exercise, you'll extract these date/time based features. A single time series has been loaded in a variable called prices.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "Calculate the day of the week, week number in a year, and month number in a year.   \n",
    "Add each one as a column to the prices_perc DataFrame, under the names day_of_week, week_of_year and month_of_year, respectively.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract date features from the data, add them as columns\n",
    "prices_perc['day_of_week'] = prices_perc.index.weekday\n",
    "prices_perc['week_of_year'] = prices_perc.index.week\n",
    "prices_perc['month_of_year'] = prices_perc.index.month\n",
    "\n",
    "# Print prices_perc\n",
    "print(prices_perc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
