{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A multi-class model\n",
    "You're going to build a model that predicts who threw which dart only based on where that dart landed! (That is the dart's x and y coordinates on the board.)  \n",
    "\n",
    "This problem is a multi-class classification problem since each dart can only be thrown by one of 4 competitors. So classes/labels are mutually exclusive, and therefore we can build a neuron with as many output as competitors and use the softmax activation function to achieve a total sum of probabilities of 1 over all competitors.  \n",
    "\n",
    "Keras Sequential model and Dense layer are already loaded for you to use.  \n",
    "\n",
    "### Instructions\n",
    "Instantiate a Sequential model.\n",
    "Add 3 dense layers of 128, 64 and 32 neurons each.  \n",
    "Add a final dense layer with as many neurons as competitors.  \n",
    "Compile your model using categorical_crossentropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a sequential model\n",
    "model = Sequential()\n",
    "  \n",
    "# Add 3 dense layers of 128, 64 and 32 neurons each\n",
    "model.add(Dense(128, input_shape=(2,), activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "  \n",
    "# Add a dense layer with as many neurons as competitors\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "  \n",
    "# Compile your model using categorical_crossentropy loss\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare your dataset\n",
    "In the console you can check that your labels, darts.competitor are not yet in a format to be understood by your network. They contain the names of the competitors as strings. You will first turn these competitors into unique numbers,then use the to_categorical() function from keras.utils to turn these numbers into their one-hot encoded representation.   \n",
    "\n",
    "This is useful for multi-class classification problems, since there are as many output neurons as classes and for every observation in our dataset we just want one of the neurons to be activated.   \n",
    "  \n",
    "The dart's dataset is loaded as darts. Pandas is imported as pd. Let's prepare this dataset!\n",
    "\n",
    "### Instructions\n",
    "Use the Categorical() method from pandas to transform the competitor column.   \n",
    "Assign a number to each competitor using the cat.codes attribute from the competitor column.   \n",
    "Import to_categorical from keras.utils.  \n",
    "Apply to_categorical() to your labels.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform into a categorical variable\n",
    "darts.competitor = pd.Categorical(darts.competitor)\n",
    "\n",
    "# Assign a number to each category (label encoding)\n",
    "darts.competitor = darts.competitor.cat.codes \n",
    "\n",
    "# Print the label encoded competitors\n",
    "print('Label encoded competitors: \\n',darts.competitor.head())\n",
    "\n",
    "# Transform into a categorical variable\n",
    "darts.competitor = pd.Categorical(darts.competitor)\n",
    "\n",
    "# Assign a number to each category (label encoding)\n",
    "darts.competitor = darts.competitor.cat.codes \n",
    "\n",
    "# Import to_categorical from keras utils module\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "coordinates = darts.drop(['competitor'], axis=1)\n",
    "# Use to_categorical on your labels\n",
    "competitors = to_categorical(darts.competitor)\n",
    "\n",
    "# Now print the one-hot encoded labels\n",
    "print('One-hot encoded competitors: \\n',competitors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on dart throwers\n",
    "Your model is now ready, just as your dataset. It's time to train!   \n",
    "\n",
    "The coordinates features and competitors labels you just transformed have been partitioned into coord_train,coord_test and competitors_train,competitors_test.   \n",
    "\n",
    "Your model is also loaded. Feel free to visualize your training data or model.summary() in the console.   \n",
    "\n",
    "Let's find out who threw which dart just by looking at the board!  \n",
    "\n",
    "### Instructions\n",
    "Train your model on the training data for 200 epochs.  \n",
    "Evaluate your model accuracy on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit your model to the training data for 200 epochs\n",
    "model.fit(coord_train, competitors_train, epochs=200)\n",
    "\n",
    "# Evaluate your model accuracy on the test data\n",
    "accuracy = model.evaluate(coord_test, competitors_test)[1]\n",
    "\n",
    "# Print accuracy\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax predictions\n",
    "Your recently trained model is loaded for you. This model is generalizing well!, that's why you got a high accuracy on the test set.   \n",
    "\n",
    "Since you used the softmax activation function, for every input of 2 coordinates provided to your model there's an output vector of 4 numbers. Each of these numbers encodes the probability of a given dart being thrown by one of the 4 possible competitors.   \n",
    "\n",
    "When computing accuracy with the model's .evaluate() method, your model takes the class with the highest probability as the prediction. np.argmax() can help you do this since it returns the index with the highest value in an array.   \n",
    "\n",
    "Use the collection of test throws stored in coords_small_test and np.argmax()to check this out!   \n",
    "\n",
    "### Instructions\n",
    "Predict with your model on coords_small_test.  \n",
    "Print the model predictions.  \n",
    "Use np.argmax()to extract the index of the highest probable competitor from each pred vector in preds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on coords_small_test\n",
    "preds = model.predict(coords_small_test)\n",
    "\n",
    "# Print preds vs true values\n",
    "print(\"{:45} | {}\".format('Raw Model Predictions','True labels'))\n",
    "for i,pred in enumerate(preds):\n",
    "  print(\"{} | {}\".format(pred,competitors_small_test[i]))\n",
    "\n",
    "# Predict on coords_small_test\n",
    "preds = model.predict(coords_small_test)\n",
    "\n",
    "# Print preds vs true values\n",
    "print(\"{:45} | {}\".format('Raw Model Predictions','True labels'))\n",
    "for i,pred in enumerate(preds):\n",
    "  print(\"{} | {}\".format(pred,competitors_small_test[i]))\n",
    "\n",
    "# Extract the position of highest probability from each pred vector\n",
    "preds_chosen = [np.argmax(pred) for pred in preds]\n",
    "\n",
    "# Print preds vs true values\n",
    "print(\"{:10} | {}\".format('Rounded Model Predictions','True labels'))\n",
    "for i,pred in enumerate(preds_chosen):\n",
    "  print(\"{:25} | {}\".format(pred,competitors_small_test[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An irrigation machine\n",
    "You're going to automate the watering of farm parcels by making an intelligent irrigation machine. Multi-label classification problems differ from multi-class problems in that each observation can be labeled with zero or more classes. So classes/labels are not mutually exclusive, you could water all, none or any combination of farm parcels based on the inputs.  \n",
    "\n",
    "To account for this behavior what we do is have an output layer with as many neurons as classes but this time, unlike in multi-class problems, each output neuron has a sigmoid activation function. This makes each neuron in the output layer able to output a number between 0 and 1 independently.   \n",
    "\n",
    "Keras Sequential() model and Dense() layers are preloaded. It's time to build an intelligent irrigation machine!\n",
    "### Instructions\n",
    "Instantiate a Sequential() model.  \n",
    "Add a hidden layer of 64 neurons with as many input neurons as there are sensors and relu activation.  \n",
    "Add an output layer with as many neurons as parcels and sigmoidactivation. \n",
    "Compile your model with the adam optimizer and binary_crossentropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add a hidden layer of 64 neurons and a 20 neuron's input\n",
    "model.add(Dense(64, activation='relu', input_shape=(20, )))\n",
    "\n",
    "# Add an output layer of 3 neurons with sigmoid activation\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "\n",
    "# Compile your model with binary crossentropy loss\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with multiple labels\n",
    "An output of your multi-label model could look like this: [0.76 , 0.99 , 0.66 ]. If we round up probabilities higher than 0.5, this observation will be classified as containing all 3 possible labels [1,1,1]. For this particular problem, this would mean watering all 3 parcels in your farm is the right thing to do, according to the network, given the input sensor measurements.   \n",
    "\n",
    "You will now train and predict with the model you just built. sensors_train, parcels_train, sensors_test and parcels_test are already loaded for you to use.  \n",
    "\n",
    "Let's see how well your intelligent machine performs!\n",
    "\n",
    "### Instructions\n",
    "Train the model for 100 epochs using a validation_split of 0.2.  \n",
    "Predict with your model using the test data.  \n",
    "Round up your preds with np.round().  \n",
    "Evaluate your model's accuracy on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train for 100 epochs using a validation split of 0.2\n",
    "model.fit(sensors_train, parcels_train, epochs=100, validation_split=.2)\n",
    "\n",
    "# Predict on sensors_test and round up the predictions\n",
    "preds = model.predict(sensors_test)\n",
    "preds_rounded = np.round(preds)\n",
    "\n",
    "# Print rounded preds\n",
    "print('Rounded Predictions: \\n', preds_rounded)\n",
    "\n",
    "# Evaluate your model's accuracy on the test data\n",
    "accuracy = model.evaluate(sensors_test, parcels_test)[1]\n",
    "\n",
    "# Print accuracy\n",
    "print('Accuracy:', accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
