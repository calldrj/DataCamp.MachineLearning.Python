{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrices\n",
    "Confusion matrices are a great way to start exploring your model's accuracy. They provide the values needed to calculate a wide range of metrics, including sensitivity, specificity, and the F1-score.   \n",
    "You have built a classification model to predict if a person has a broken arm based on an X-ray image. On the testing set, you have the following confusion matrix:   \n",
    "Prediction: 0\tPrediction: 1    \n",
    "Actual: 0\t324 (TN)\t15 (FP)    \n",
    "Actual: 1\t123 (FN)\t491 (TP)   \n",
    "### Instructions   \n",
    "Use the confusion matrix to calculate overall accuracy.   \n",
    "Use the confusion matrix to calculate precision and recall.   \n",
    "Use the three print statements to print each accuracy value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and print the accuracy\n",
    "accuracy = (491 + 324) / (953)\n",
    "print(\"The overall accuracy is {0: 0.2f}\".format(accuracy))\n",
    "\n",
    "# Calculate and print the precision\n",
    "precision = (491) / (491 + 15)\n",
    "print(\"The precision is {0: 0.2f}\".format(precision))\n",
    "\n",
    "# Calculate and print the recall\n",
    "recall = (491) / (491 + 123)\n",
    "print(\"The recall is {0: 0.2f}\".format(recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrices, again\n",
    "Creating a confusion matrix in Python is simple. The biggest challenge will be making sure you understand the orientation of the matrix.    \n",
    "This exercise makes sure you understand the sklearn implementation of confusion matrices. Here, you have created a random forest model using the tic_tac_toe dataset rfc to predict outcomes of 0 (loss) or 1 (a win) for Player One.\n",
    "Note: If you read about confusion matrices on another website or for another programming language, the values might be reversed.\n",
    "### Instructions\n",
    "Import sklearn's function for creating confusion matrices.   \n",
    "Using the model rfc, create category predictions on the test set X_test.   \n",
    "Create a confusion matrix using sklearn.   \n",
    "Print the value from cm that represents the actual 1s that were predicted as 1s (true positives)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Create predictions\n",
    "test_predictions = rfc.predict(X_test)\n",
    "\n",
    "# Create and print the confusion matrix\n",
    "cm = confusion_matrix(y_test, test_predictions)\n",
    "print(cm)\n",
    "\n",
    "# Print the true positives (actual 1s that were predicted 1s)\n",
    "print(\"The number of true positives is: {}\".format(cm[1,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<script.py> output:    \n",
    "    [[177 123]    \n",
    "     [ 92 471]]     \n",
    "    The number of true positives is: 471\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision vs. recall\n",
    "The accuracy metrics you use to evaluate your model should always be based on the specific application. For this example, let's assume you are a really sore loser when it comes to playing Tic-Tac-Toe, but only when you are certain that you are going to win.   \n",
    "Choose the most appropriate accuracy metric, either precision or recall, to complete this example. But remember, if you think you are going to win, you better win!     \n",
    "Use rfc, which is a random forest classification model built on the tic_tac_toe dataset.   \n",
    "### Instructions\n",
    "Import the precision or the recall metric for sklearn. Only one method is correct for the given context.    \n",
    "Calculate the precision or recall using y_test for the true values and test_predictions for the predictions.    \n",
    "Print the final score based on your selected metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "test_predictions = rfc.predict(X_test)\n",
    "\n",
    "# Create precision or recall score based on the metric you imported\n",
    "score = precision_score(y_test, test_predictions)\n",
    "\n",
    "# Print the final result\n",
    "print(\"The precision value is {0:.2f}\".format(score))\n",
    "\"\"\" Precision is the correct metric here. \n",
    "Sore-losers can't stand losing when they are certain they will win! \n",
    "For that reason, our model needs to be as precise as possible. \n",
    "With a precision of only 79%, you may need to try some other \n",
    "modeling techniques to improve this score.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error due to under/over-fitting\n",
    "The candy dataset is prime for overfitting. With only 85 observations, if you use 20% for the testing dataset, you are losing a lot of vital data that could be used for modeling. Imagine the scenario where most of the chocolate candies ended up in the training data and very few in the holdout sample. Our model might only see that chocolate is a vital factor, but fail to find that other attributes are also important. In this exercise, you'll explore how using too many features (columns) in a random forest model can lead to overfitting.   \n",
    "A feature represents which columns of the data are used in a decision tree. The parameter max_features limits the number of features available.\n",
    "### Instructions \n",
    "Create a random forest model with 25 trees, a random state of 1111, and max_features of 2. Read the print statements.  \n",
    "Set max_features to 11 (the number of columns in the dataset). Read the print statements.   \n",
    "Set max_features equal to 4. Read the print statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the rfr model\n",
    "rfr = RandomForestRegressor(n_estimators=25,\n",
    "                            random_state=1111,\n",
    "                            max_features=2)\n",
    "rfr.fit(X_train, y_train)\n",
    "\n",
    "# Print the training and testing accuracies \n",
    "print('The training error is {0:.2f}'.format(\n",
    "  mae(y_train, rfr.predict(X_train))))\n",
    "print('The testing error is {0:.2f}'.format(\n",
    "  mae(y_test, rfr.predict(X_test))))\n",
    "\"\"\"\n",
    "The training error is 3.88\n",
    "The testing error is 9.15\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the rfr model\n",
    "rfr = RandomForestRegressor(n_estimators=25,\n",
    "                            random_state=1111,\n",
    "                            max_features=____)\n",
    "rfr.fit(X_train, y_train)\n",
    "\n",
    "# Print the training and testing accuracies \n",
    "print('The training error is {0:.2f}'.format(\n",
    "  mae(y_train, rfr.predict(X_train))))\n",
    "print('The testing error is {0:.2f}'.format(\n",
    "  mae(y_test, rfr.predict(X_test))))\n",
    "\"\"\"\n",
    "The training error is 3.57\n",
    "The testing error is 10.05\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the rfr model\n",
    "rfr = RandomForestRegressor(n_estimators=25,\n",
    "                            random_state=1111,\n",
    "                            max_features=4)\n",
    "rfr.fit(X_train, y_train)\n",
    "\n",
    "# Print the training and testing accuracies \n",
    "print('The training error is {0:.2f}'.format(\n",
    "  mae(y_train, rfr.predict(X_train))))\n",
    "print('The testing error is {0:.2f}'.format(\n",
    "  mae(y_test, rfr.predict(X_test))))\n",
    "\n",
    "\"\"\"\n",
    "The training error is 3.60\n",
    "The testing error is 8.79\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Am I underfitting?\n",
    "You are creating a random forest model to predict if you will win a future game of Tic-Tac-Toe. Using the tic_tac_toe dataset, you have created training and testing datasets, X_train, X_test, y_train, and y_test.    \n",
    "You have decided to create a bunch of random forest models with varying amounts of trees (1, 2, 3, 4, 5, 10, 20, and 50). The more trees you use, the longer your random forest model will take to run. However, if you don't use enough trees, you risk underfitting. You have created a for loop to test your model at the different number of trees.\n",
    "### Instructions\n",
    "For each loop, predict values for both the X_train and X_test datasets.     \n",
    "For each loop, append the accuracy_score() of the y_train dataset and the corresponding predictions to train_scores.    \n",
    "For each loop, append the accuracy_score() of the y_test dataset and the corresponding predictions to test_scores.\n",
    "Print the training and testing scores using the print statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "test_scores, train_scores = [], []\n",
    "for i in [1, 2, 3, 4, 5, 10, 20, 50]:\n",
    "    rfc = RandomForestClassifier(n_estimators=i, random_state=1111)\n",
    "    rfc.fit(X_train, y_train)\n",
    "    # Create predictions for the X_train and X_test datasets.\n",
    "    train_predictions = rfc.predict(X_train)\n",
    "    test_predictions = rfc.predict(X_test)\n",
    "    # Append the accuracy score for the test and train predictions.\n",
    "    train_scores.append(round(accuracy_score(y_train, train_predictions), 2))\n",
    "    test_scores.append(round(accuracy_score(y_test, test_predictions), 2))\n",
    "# Print the train and test scores.\n",
    "print(\"The training scores were: {}\".format(train_scores))\n",
    "print(\"The testing scores were: {}\".format(test_scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
