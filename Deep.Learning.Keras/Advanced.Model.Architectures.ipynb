{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It's a flow of tensors\n",
    "If you have already built a model, you can use the model.layers and the keras.backend to build functions that, provided with a valid input tensor, return the corresponding output tensor.   \n",
    "\n",
    "This is a useful tool when we want to obtain the output of a network at an intermediate layer.  \n",
    "\n",
    "For instance, if you get the input and output from the first layer of a network, you can build an inp_to_out function that returns the result of carrying out forward propagation through only the first layer for a given input tensor.  \n",
    "\n",
    "So that's what you're going to do right now!  \n",
    "\n",
    "X_test from the Banknote Authentication dataset and its model are preloaded. Type model.summary() in the console to check it. \n",
    "\n",
    "### Instructions\n",
    "Import keras.backend as K.\n",
    "Use the model.layers list to get a reference to the input and output of the first layer.\n",
    "Use K.function() to define a function that maps inp to out.\n",
    "Print the results of passing X_test through the 1st layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import keras backend\n",
    "import keras.backend as K\n",
    "\n",
    "# Input tensor from the 1st layer of the model\n",
    "inp = model.layers[0].input\n",
    "\n",
    "# Output tensor from the 1st layer of the model\n",
    "out = model.layers[0].output\n",
    "\n",
    "# Define a function from inputs to outputs\n",
    "inp_to_out = K.function([inp], [out])\n",
    "\n",
    "# Print the results of passing X_test through the 1st layer\n",
    "print(inp_to_out([X_test]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural separation\n",
    "Put on your gloves because you're going to perform brain surgery!  \n",
    "\n",
    "Neurons learn by updating their weights to output values that help them better distinguish between the different output classes in your dataset. You will make use of the inp_to_out() function you just built to visualize the output of two neurons in the first layer of the Banknote Authentication model as it learns.  \n",
    "\n",
    "The model you built in chapter 2 is ready for you to use, just like X_test and y_test. Paste show_code(plot) in the console if you want to check plot().  \n",
    "\n",
    "You're performing heavy duty, once all is done, click through the graphs to watch the separation live!  \n",
    "\n",
    "### Instructions\n",
    "Use the previously defined inp_to_out() function to get the outputs of the first layer when fed with X_test.\n",
    "Use the model.evaluate() method to obtain the validation accuracy for the test dataset at each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 21):\n",
    "  \t# Train model for 1 epoch\n",
    "    h = model.fit(X_train, y_train, batch_size=16, epochs=1, verbose=0)\n",
    "    if i%4==0: \n",
    "      # Get the output of the first layer\n",
    "      layer_output = inp_to_out([X_test])[0]\n",
    "      \n",
    "      # Evaluate model accuracy for this epoch\n",
    "      test_accuracy = model.evaluate(X_test, y_test)[1] \n",
    "      \n",
    "      # Plot 1st vs 2nd neuron output\n",
    "      plot()\n",
    "        \n",
    "def plot():\n",
    "  fig, ax = plt.subplots()\n",
    "  plt.scatter(layer_output[:, 0], layer_output[:, 1], c=y_test,  edgecolors='none')\n",
    "  plt.title('Epoch: {}, Test Accuracy: {:3.1f} %'.format(i+1, test_accuracy * 100.0))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building an autoencoder\n",
    "Autoencoders have several interesting applications like anomaly detection or image denoising. They aim at producing an output identical to its inputs. The input will be compressed into a lower dimensional space, encoded. The model then learns to decode it back to its original form.   \n",
    "\n",
    "You will encode and decode the MNIST dataset of handwritten digits, the hidden layer will encode a 32-dimensional representation of the image, which originally consists of 784 pixels (28 x 28). The autoencoder will essentially learn to turn the 784 pixels original image into a compressed 32 pixels image and learn how to use that encoded representation to bring back the original 784 pixels image.  \n",
    "\n",
    "The Sequential model and Dense layers are ready for you to use.  \n",
    "\n",
    "Let's build an autoencoder!\n",
    "\n",
    "### Instructions\n",
    "Create a Sequential model.  \n",
    "Add a dense layer with as many neurons as the encoded image dimensions and input_shape the number of pixels in the original image.  \n",
    "Add a final layer with as many neurons as pixels in the input image.  \n",
    "Compile your autoencoder using adadelta as an optimizer and binary_crossentropy loss, then summarise it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with a sequential model\n",
    "autoencoder = Sequential()\n",
    "\n",
    "# Add a dense layer with input the original image pixels and neurons the encoded representation\n",
    "autoencoder.add(Dense(32, input_shape=(784, ), activation='relu'))\n",
    "\n",
    "# Add an output layer with as many neurons as the orginal image pixels\n",
    "autoencoder.add(Dense(784, activation='sigmoid'))\n",
    "\n",
    "# Compile your model with adadelta\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "\n",
    "# Summarize your model structure\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### De-noising like an autoencoder\n",
    "You have just built an autoencoder model. Let's see how it handles a more challenging task. \n",
    "\n",
    "First, you will build a model that encodes images, and you will check how different digits are represented with show_encodings(). To build the encoder you will make use of your autoencoder, that has already being trained. You will just use the first half of the network, which contains the input and the bottleneck output. That way, you will obtain a 32 number output which represents the encoded version of the input image. \n",
    "\n",
    "Then, you will apply your autoencoder to noisy images from MNIST, it should be able to clean the noisy artifacts. \n",
    "\n",
    "X_test_noise is loaded in your workspace. The digits in this noisy dataset look like this:  \n",
    "Apply the power of the autoencoder!\n",
    "### Instructions \n",
    "Build an encoder model with the first layer of your trained autoencoder model.   \n",
    "Predict on X_test_noise with your encoder and show the results with show_encodings().     \n",
    "Plot noisy vs decoded images with compare_plot()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build your encoder by using the first layer of your autoencoder\n",
    "encoder = Sequential()\n",
    "encoder.add(autoencoder.layers[0])\n",
    "\n",
    "# Encode the noisy images and show the encodings for your favorite number [0-9]\n",
    "encodings = encoder.predict(X_test_noise)\n",
    "show_encodings(encodings, number = 1)\n",
    "\n",
    "# Predict on the noisy images with your autoencoder\n",
    "decoded_imgs = autoencoder.predict(X_test_noise)\n",
    "\n",
    "# Plot noisy vs decoded images\n",
    "compare_plot(X_test_noise, decoded_imgs)\n",
    "\n",
    "\"\"\" Amazing! The noise is gone now! You could get a better reconstruction by using \n",
    "a convolutional autoencoder. I hope this new model opened up your mind to the many \n",
    "possible architectures and non-classical ML problems that neural networks can solve.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
