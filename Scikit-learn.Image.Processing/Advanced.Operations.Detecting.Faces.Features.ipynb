{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edges\n",
    "In this exercise you will identify the shapes in a grapefruit image by detecting the edges, using the Canny algorithm.   \n",
    "Image preloaded as grapefruit.  \n",
    "The color module has already been preloaded for you.\n",
    "\n",
    "### Instructions\n",
    "Import the canny edge detector from the feature module.   \n",
    "Convert the image to grayscale, using the method from the color module used in previous chapters.  \n",
    "Apply the canny edge detector to the grapefruit image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the canny edge detector \n",
    "from skimage.feature import canny\n",
    "\n",
    "# Convert image to grayscale\n",
    "grapefruit = color.rgb2gray(grapefruit)\n",
    "\n",
    "# Apply canny edge detector\n",
    "canny_edges = canny(grapefruit)\n",
    "\n",
    "# Show resulting image\n",
    "show_image(canny_edges, \"Edges with Canny\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Less edgy\n",
    "Let's now try to spot just the outer shape of the grapefruits, the circles. You can do this by applying a more intense Gaussian filter to first make the image smoother. This can be achieved by specifying a bigger sigma in the canny function.  \n",
    "\n",
    "In this exercise, you'll experiment with sigma values of the canny() function.  \n",
    "\n",
    "Image preloaded as grapefruit.  \n",
    "The show_image has already been preloaded.\n",
    "\n",
    "### Instructions \n",
    "Apply the canny edge detector to the grapefruit image with a sigma of 1.8.   \n",
    "Apply the canny edge detector to the grapefruit image with a sigma of 2.2.   \n",
    "Show the resulting images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply canny edge detector with a sigma of 1.8\n",
    "edges_1_8 = canny(grapefruit, sigma=1.8)\n",
    "\n",
    "# Apply canny edge detector with a sigma of 2.2\n",
    "edges_2_2 = canny(grapefruit, sigma=2.2)\n",
    "\n",
    "# Show resulting images\n",
    "show_image(edges_1_8, \"Sigma of 1.8\")\n",
    "show_image(edges_2_2, \"Sigma of 2.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perspective\n",
    "In this exercise, you will detect the corners of a building using the Harris corner detector.  \n",
    "\n",
    "Image preloaded as building_image.  \n",
    "The functions show_image() and show_image_with_corners() have already been preloaded for you.   \n",
    "As well as the color module for converting images to grayscale.  \n",
    "\n",
    "### Instructions\n",
    "Import the corner_harris() function from the feature module.  \n",
    "Convert the building_image to grayscale.  \n",
    "Apply the harris detector to obtain the measure response image with the possible corners.  \n",
    "Find the peaks of the corners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the corner detector related functions and module\n",
    "from skimage.feature import corner_harris, corner_peaks\n",
    "\n",
    "# Convert image from RGB-3 to grayscale\n",
    "building_image_gray = color.rgb2gray(building_image)\n",
    "\n",
    "# Apply the detector  to measure the possible corners\n",
    "measure_image = corner_harris(building_image_gray)\n",
    "\n",
    "# Find the peaks of the corners using the Harris detector\n",
    "coords = corner_peaks(measure_image, min_distance=2)\n",
    "\n",
    "# Show original and resulting image with corners detected\n",
    "show_image(building_image, \"Original\")\n",
    "show_image_with_corners(building_image, coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Less corners\n",
    "In this exercise, you will test what happens when you set the minimum distance between corner peaks to be a higher number. Remember you do this with the min_distance attribute parameter of the corner_peaks() function.  \n",
    "\n",
    "Image preloaded as building_image.  \n",
    "The functions show_image(), show_image_with_corners() and required packages have already been preloaded for you. As well as all the previous code for finding the corners.   \n",
    "The Harris measure response image obtained with corner_harris() is preloaded as measure_image.  \n",
    "\n",
    "Instructions \n",
    "Find the peaks of the corners with a minimum distance of 2 pixels.   \n",
    "Find the peaks of the corners with a minimum distance of 40 pixels.  \n",
    "Show original and resulting image with corners detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_with_corners(image, coords, title=\"Corners detected\"):    \n",
    "    plt.imshow(image, interpolation='nearest', cmap='gray')    \n",
    "    plt.title(title)    \n",
    "    plt.plot(coords[:, 1], coords[:, 0], '+r', markersize=15)    \n",
    "    plt.axis('off')    \n",
    "    plt.show()\n",
    "\n",
    "# Find the peaks with a min distance of 2 pixels\n",
    "coords_w_min_2 = corner_peaks(measure_image, min_distance=2)\n",
    "print(\"With a min_distance set to 2, we detect a total\", len(coords_w_min_2), \"corners in the image.\")\n",
    "\n",
    "# Find the peaks with a min distance of 40 pixels\n",
    "coords_w_min_40 = corner_peaks(measure_image, min_distance=40)\n",
    "print(\"With a min_distance set to 40, we detect a total\", len(coords_w_min_40), \"corners in the image.\")\n",
    "\n",
    "# Show original and resulting image with corners detected\n",
    "show_image_with_corners(building_image, coords_w_min_2, \"Corners detected with 2 px of min_distance\")\n",
    "show_image_with_corners(building_image, coords_w_min_40, \"Corners detected with 40 px of min_distance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is someone there?\n",
    "In this exercise, you will check whether or not there is a person present in an image taken at night.  \n",
    "\n",
    "LAndscape of starry night with a young man in the left bottom corner  \n",
    "Image preloaded as night_image.  \n",
    "The Cascade of classifiers class from feature module has been already imported.  \n",
    "The same is true for the show_detected_face() function, that is used to display the face marked in the image and crop so it can be shown separately.\n",
    "\n",
    "### Instructions\n",
    "Load the trained file from the data module.  \n",
    "Initialize the detector cascade with the trained file.  \n",
    "Detect the faces in the image, setting the minimum size of the searching window to 10 pixels and 200 pixels for the maximum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_detected_face(result, detected, title=\"Face image\"):    \n",
    "    plt.imshow(result)    \n",
    "    img_desc = plt.gca()    \n",
    "    plt.set_cmap('gray')    \n",
    "    plt.title(title)    \n",
    "    plt.axis('off')\n",
    "    for patch in detected:        \n",
    "        img_desc.add_patch(            \n",
    "            patches.Rectangle(                \n",
    "                (patch['c'], patch['r']),                \n",
    "                 patch['width'],                \n",
    "                 patch['height'],                \n",
    "                 fill=False, \n",
    "                 color='r',\n",
    "                 linewidth=2)        \n",
    "        )    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained file from data\n",
    "trained_file = data.lbp_frontal_face_cascade_filename()\n",
    "\n",
    "# Initialize the detector cascade\n",
    "detector = Cascade(trained_file)\n",
    "\n",
    "# Detect faces with min and max size of searching window\n",
    "detected = detector.detect_multi_scale(img = night_image,\n",
    "                                       scale_factor=1.2,\n",
    "                                       step_ratio=1,\n",
    "                                       min_size=(10, 10),\n",
    "                                       max_size=(200, 200))\n",
    "\n",
    "# Show the detected faces\n",
    "show_detected_face(night_image, detected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple faces\n",
    "In this exercise, you will detect multiple faces in an image and show them individually. Think of this as a way to create a dataset of your own friends' faces!  \n",
    "\n",
    "Image preloaded as friends_image.  \n",
    "The Cascade of classifiers class from feature module has already been imported, as well as the show_detected_face() function which is used to display the face marked in the image and crop it so it can be shown separately.\n",
    "\n",
    "### Instructions\n",
    "Load the trained file from the data module.  \n",
    "Initialize the detector cascade with trained file.  \n",
    "Detect the faces in the image, setting a scale_factor of 1.2 and step_ratio of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained file from data\n",
    "trained_file = data.lbp_frontal_face_cascade_filename()\n",
    "\n",
    "# Initialize the detector cascade\n",
    "detector = Cascade(trained_file)\n",
    "\n",
    "# Detect faces with scale factor to 1.2 and step ratio to 1\n",
    "detected = detector.detect_multi_scale(img=friends_image,\n",
    "                                       scale_factor=1.2,\n",
    "                                       step_ratio=1,\n",
    "                                       min_size=(10, 10),\n",
    "                                       max_size=(200, 200))\n",
    "# Show the detected faces\n",
    "show_detected_face(friends_image, detected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentation and face detection\n",
    "Previously, you learned how to make processes more computationally efficient with unsupervised superpixel segmentation. In this exercise, you'll do just that!  \n",
    "\n",
    "Using the slic() function for segmentation, pre-process the image before passing it to the face detector.  \n",
    "\n",
    "Image preloaded as profile_image.  \n",
    "The Cascade class, the slic() function from segmentation module, and the show_detected_face() function for visualization have already been imported. The detector is already initialized and ready to use as detector.  \n",
    "\n",
    "### Instructions\n",
    "Apply superpixel segmentation and obtain the segments a.k.a. labels using slic().  \n",
    "Obtain the segmented image using label2rgb(), passing the segments and profile_image.  \n",
    "Detect the faces, using the detector with multi scale method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the segmentation with default 100 regions\n",
    "segments = slic(image=profile_image, n_segments=100)\n",
    "\n",
    "# Obtain segmented image using label2rgb\n",
    "segmented_image = label2rgb(segments, profile_image, kind='avg')\n",
    "\n",
    "# Detect the faces with multi scale method\n",
    "detected = detector.detect_multi_scale(img=segmented_image, \n",
    "                                       scale_factor=1.2, \n",
    "                                       step_ratio=1, \n",
    "                                       min_size=(10, 10), \n",
    "                                       max_size=(1000, 1000))\n",
    "\n",
    "# Show the detected faces\n",
    "show_detected_face(segmented_image, detected)\n",
    "\n",
    "\"\"\" You applied segementation to the image before passing it to the face detector and \n",
    "it's finding the face even when the image is relatively large.\n",
    "This time you used 1000 by 1000 pixels as the maximum size of the searching window \n",
    "because the face in this case was indeed rather larger in comparison to the image.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Privacy Protection\n",
    "In this exercise, you will detect human faces in the image and for the sake of privacy, you will anonymize data by blurring people's faces in the image automatically.   \n",
    "  \n",
    "Image preloaded as group_image.   \n",
    "You can use the gaussian filter for the blurriness.  \n",
    "\n",
    "The face detector is ready to use as detector and all packages needed have been imported.  \n",
    "\n",
    "### Instructions\n",
    "Detect the faces in the image using the detector, set the minimum size of the searching window to 10 by 10 pixels.  \n",
    "Go through each detected face with a for loop.  \n",
    "Apply a gaussian filter to detect and blur faces, using a sigma of 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeBlurryFace(original, gaussian_image):\n",
    "    # X and Y starting points of the face rectangle    \n",
    "    x, y  = d['r'], d['c']\n",
    "    # The width and height of the face rectangle    \n",
    "    width, height = d['r'] + d['width'],  d['c'] + d['height']    \n",
    "    original[ x:width, y:height] =  gaussian_image\n",
    "    return original\n",
    "\n",
    "# Detect the faces\n",
    "detected = detector.detect_multi_scale(img=group_image, \n",
    "                                       scale_factor=1.2, \n",
    "                                       step_ratio=1, \n",
    "                                       min_size=(10, 10),\n",
    "                                       max_size=(100, 100))\n",
    "# For each detected face\n",
    "for d in detected:  \n",
    "    # Obtain the face rectangle from detected coordinates\n",
    "    face = getFaceRectangle(d)\n",
    "    \n",
    "    # Apply gaussian filter to extracted face\n",
    "    blurred_face = gaussian(image=face, multichannel=True, sigma=8)\n",
    "    \n",
    "    # Merge this blurry face to our final image and show it\n",
    "    resulting_image = mergeBlurryFace(group_image, blurred_face) \n",
    "show_image(resulting_image, \"Blurred faces\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Help Sally restore her graduation photo\n",
    "You are going to combine all the knowledge you acquired throughout the course to complete a final challenge: reconstructing a very damaged photo.   \n",
    "\n",
    "Help Sally restore her favorite portrait which was damaged by noise, distortion, and missing information due to a breach in her laptop.   \n",
    "\n",
    "Sally's damaged portrait is already loaded as damaged_image.  \n",
    "You will be fixing the problems of this image by:  \n",
    "\n",
    "Rotating it to be upright using rotate()  \n",
    "Applying noise reduction with denoise_tv_chambolle()  \n",
    "Reconstructing the damaged parts with inpaint_biharmonic() from the inpaint module.  \n",
    "show_image() is already preloaded.  \n",
    "\n",
    "### Instructions\n",
    "Import the necessary module to apply restoration on the image.  \n",
    "Rotate the image by calling the function rotate().  \n",
    "Use the chambolle algorithm to remove the noise from the image.  \n",
    "With the mask provided, use the biharmonic method to restore the missing parts of the image and obtain the final image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary modules\n",
    "from skimage.restoration import denoise_tv_chambolle, inpaint\n",
    "from skimage import transform\n",
    "\n",
    "# Transform the image so it's not rotated\n",
    "upright_img = rotate(damaged_image, 20)\n",
    "\n",
    "# Remove noise from the image, using the chambolle method\n",
    "upright_img_without_noise = denoise_tv_chambolle(upright_img,weight=0.1, multichannel=True)\n",
    "\n",
    "# Reconstruct the image missing parts\n",
    "mask = get_mask(upright_img)\n",
    "result = inpaint.inpaint_biharmonic(upright_img_without_noise, mask, multichannel=True)\n",
    "\n",
    "show_image(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
