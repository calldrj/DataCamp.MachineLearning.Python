{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the learning curves\n",
    "During learning, the model will store the loss function evaluated in each epoch. Looking at the learning curves can tell us quite a bit about the learning process. In this exercise, you will plot the learning and validation loss curves for a model that you will train.  \n",
    "\n",
    "### Instructions\n",
    "Fit the model to the training data (train_data).   \n",
    "Use a validation split of 20%, 3 epochs and batch size of 10.  \n",
    "Plot the training loss.  \n",
    "Plot the validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Train the model and store the training object\n",
    "training = model.fit(train_data, train_labels, validation_split=.2, epochs=3, batch_size=10)\n",
    "\n",
    "# Extract the history from the training object\n",
    "history = training.history\n",
    "\n",
    "# Plot the training loss \n",
    "plt.plot(history['loss'])\n",
    "# Plot the validation loss\n",
    "plt.plot(history['val_loss'])\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using stored weights to predict in a test set\n",
    "Model weights stored in an hdf5 file can be reused to populate an untrained model. Once the weights are loaded into this model, it behaves just like a model that has been trained to reach these weights. For example, you can use this model to make predictions from an unseen data set (e.g. test_data).  \n",
    "\n",
    "### Instructions\n",
    "Load the weights from a file called 'weights.hdf5'.  \n",
    "Predict the classes of the first three images from test_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the weights from file\n",
    "model.load_weights('weights.hdf5')\n",
    "\n",
    "# Predict from the first three images in the test data\n",
    "model.predict(test_data[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding dropout to your network\n",
    "Dropout is a form of regularization that removes a different random subset of the units in a layer in each round of training. In this exercise, we will add dropout to the convolutional neural network that we have used in previous exercises:   \n",
    "\n",
    "Convolution (15 units, kernel size 2, 'relu' activation)  \n",
    "Dropout (20%)  \n",
    "Convolution (5 units, kernel size 2, 'relu' activation)  \n",
    "Flatten  \n",
    "Dense (3 units, 'softmax' activation)  \n",
    "A Sequential model along with Dense, Conv2D, Flatten, and Dropout objects are available in your workspace.\n",
    "\n",
    "### Instructions\n",
    "Add dropout applied to the first layer with 20%.  \n",
    "Add a flattening layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a convolutional layer\n",
    "model.add(Conv2D(15, kernel_size=2, activation='relu', \n",
    "                 input_shape=(img_rows, img_cols, 1)))\n",
    "\n",
    "# Add a dropout layer\n",
    "model.add(Dropout(.2))\n",
    "\n",
    "# Add another convolutional layer\n",
    "model.add(Conv2D(5, kernel_size=2, activation='relu'))\n",
    "\n",
    "# Flatten and feed to output layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add batch normalization to your network\n",
    "Batch normalization is another form of regularization that rescales the outputs of a layer to make sure that they have mean 0 and standard deviation 1. In this exercise, we will add batch normalization to the convolutional neural network that we have used in previous exercises:  \n",
    "\n",
    "Convolution (15 units, kernel size 2, 'relu' activation)  \n",
    "Batch normalization  \n",
    "Convolution (5 unites, kernel size 2, 'relu' activation)  \n",
    "Flatten  \n",
    "Dense (3 units, 'softmax' activation) \n",
    "A Sequential model along with Dense, Conv2D, Flatten, and Dropout objects are available in your workspace.    \n",
    "\n",
    "### Instructions\n",
    "Add the first convolutional layer. You can use the img_rows and img_cols objects available in your workspace to define the input_shape of this layer.   \n",
    "Add batch normalization applied to the outputs of the first layer.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a convolutional layer\n",
    "model.add(Conv2D(15, activation='relu', kernel_size=2, input_shape=(img_rows, img_cols, 1)))\n",
    "\n",
    "# Add batch normalization layer\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Add another convolutional layer\n",
    "model.add(Conv2D(5, kernel_size=2, activation='relu'))\n",
    "\n",
    "# Flatten and feed to output layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting a kernel from a trained network\n",
    "One way to interpret models is to examine the properties of the kernels in the convolutional layers.  \n",
    "In this exercise, you will extract one of the kernels from a convolutional neural network with weights that you saved in a hdf5 file.\n",
    "\n",
    "### Instructions\n",
    "Load the weights into the model from the file weights.hdf5.  \n",
    "Get the first convolutional layer in the model from the layers attribute.  \n",
    "Use the .get_weights() method to extract the weights from this layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the weights into the model\n",
    "model.load_weights('weights.hdf5')\n",
    "\n",
    "# Get the first convolutional layer from the model\n",
    "c1 = model.layers[0]\n",
    "\n",
    "# Get the weights of the first convolutional layer\n",
    "weights1 = c1.get_weights()\n",
    "\n",
    "# Pull out the first channel of the first kernel in the first layer\n",
    "kernel = weights1[0][..., 0, 0]\n",
    "print(kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing kernel responses\n",
    "One of the ways to interpret the weights of a neural network is to see how the kernels stored in these weights \"see\" the world. That is, what properties of an image are emphasized by this kernel.   \n",
    "In this exercise, we will do that by convolving an image with the kernel and visualizing the result. Given images in the test_data variable, a function called extract_kernel() that extracts a kernel from the provided network, and the function called convolution() that we defined in the first chapter, extract the kernel, load the data from a file and visualize it with matplotlib.   \n",
    "\n",
    "A deep CNN model, a function convolution(), along with the kernel you extracted in an earlier exercise is available in your workspace.  \n",
    "\n",
    "Ready to take your deep learning to the next level? Check out Advanced Deep Learning with Keras in Python to see how the Keras functional API lets you build domain knowledge to solve new types of problems.\n",
    "\n",
    "### Instructions\n",
    "Use the convolution() function to convolve the extracted kernel with the first channel of the fourth item in the image array.   \n",
    "Visualize the resulting convolution with imshow()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convolve with the fourth image in test_data\n",
    "out = convolution(test_data[3, :, :, 0], kernel)\n",
    "\n",
    "# Visualize the result\n",
    "plt.imshow(out)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
