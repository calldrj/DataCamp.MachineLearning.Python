{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's restore a damaged image\n",
    "In this exercise, we'll restore an image that has missing parts in it, using the inpaint_biharmonic() function.   \n",
    "\n",
    "Loaded as defect_image.  \n",
    "We'll work on an image from the data module, obtained by data.astronaut(). Some of the pixels have been replaced by 1s using a binary mask, on purpose, to simulate a damaged image. Replacing pixels with 1s turns them totally black. The defective image is saved as an array called defect_image.   \n",
    "\n",
    "The mask is a black and white image with patches that have the position of the image bits that have been corrupted. We can apply the restoration function on these areas. This mask is preloaded as mask.  \n",
    "\n",
    "Remember that inpainting is the process of reconstructing lost or deteriorated parts of images and videos.\n",
    "\n",
    "### Instructions \n",
    "Import the inpaint function in the restoration module in scikit-image (skimage).  \n",
    "Show the defective image using show_image().  \n",
    "Call the correct function from inpaint. Use the corrupted image as the first parameter, then the mask and multichannel boolean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the module from restoration\n",
    "from skimage.restoration import inpaint\n",
    "\n",
    "# Show the defective image\n",
    "show_image(defect_image, 'Image to restore')\n",
    "\n",
    "# Apply the restoration function to the image using the mask\n",
    "restored_image = inpaint.inpaint_biharmonic(defect_image, mask, multichannel=True)\n",
    "show_image(restored_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing logos\n",
    "As we saw in the video, another use of image restoration is removing objects from an scene. In this exercise, we'll remove the Datacamp logo from an image.\n",
    "\n",
    "Image loaded as image_with_logo.  \n",
    "You will create and set the mask to be able to erase the logo by inpainting this area.  \n",
    "\n",
    "Remember that when you want to remove an object from an image you can either manually delineate that object or run some image analysis algorithm to find it.  \n",
    "\n",
    "### Instructions\n",
    "Initialize a mask with the same shape as the image, using np.zeros().  \n",
    "In the mask, set the region that will be inpainted to 1 .  \n",
    "Apply inpainting to image_with_logo using the mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the mask\n",
    "mask = np.zeros(image_with_logo.shape[:-1])\n",
    "\n",
    "# Set the pixels where the logo is to 1\n",
    "mask[210:272, 360:425] = 1\n",
    "\n",
    "# Apply inpainting to remove the logo\n",
    "image_logo_removed = inpaint.inpaint_biharmonic(image_with_logo,\n",
    "                                                mask,\n",
    "                                                multichannel=True)\n",
    "\n",
    "# Show the original and logo removed images\n",
    "show_image(image_with_logo, 'Image with logo')\n",
    "show_image(image_logo_removed, 'Image with logo removed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's make some noise!\n",
    "In this exercise, we'll practice adding noise to a fruit image.\n",
    "\n",
    "Image preloaded as fruit_image.  \n",
    "### Instructions\n",
    "Import the util module and the random noise function.      \n",
    "Add noise to the image.   \n",
    "Show the original and resulting image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the module and function\n",
    "from skimage.util import random_noise\n",
    "\n",
    "# Add noise to the image\n",
    "noisy_image = random_noise(fruit_image)\n",
    "\n",
    "# Show original and resulting image\n",
    "show_image(fruit_image, 'Original')\n",
    "show_image(noisy_image, 'Noisy image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing noise\n",
    "We have a noisy image that we want to improve by removing the noise in it.\n",
    "\n",
    "Preloaded as noisy_image.     \n",
    "Use total variation filter denoising to accomplish this.\n",
    "\n",
    "### Instructions\n",
    "Import the denoise_tv_chambolle function from its module.    \n",
    "Apply total variation filter denoising.  \n",
    "Show the original noisy and the resulting denoised image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the module and function\n",
    "from skimage.restoration import denoise_tv_chambolle\n",
    "\n",
    "# Apply total variation filter denoising\n",
    "denoised_image = denoise_tv_chambolle(noisy_image, \n",
    "                                      multichannel=True)\n",
    "\n",
    "# Show the noisy and denoised images\n",
    "show_image(noisy_image, 'Noisy')\n",
    "show_image(denoised_image, 'Denoised image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing noise while preserving edges\n",
    "In this exercise, you will reduce the noise in this landscape picture.  \n",
    "\n",
    "Preloaded as landscape_image.  \n",
    "Since we prefer to preserve the edges in the image, we'll use the bilateral denoising filter.\n",
    "\n",
    "### Instructions\n",
    "Import the denoise_bilateral function from its module.  \n",
    "Apply bilateral filter denoising.\n",
    "Show the original noisy and the resulting denoised image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import bilateral denoising function\n",
    "from skimage.restoration import denoise_bilateral\n",
    "\n",
    "# Apply bilateral filter denoising\n",
    "denoised_image = denoise_bilateral(landscape_image, \n",
    "                                   multichannel=True)\n",
    "\n",
    "# Show original and resulting images\n",
    "show_image(landscape_image, 'Noisy image')\n",
    "show_image(denoised_image, 'Denoised image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Superpixel segmentation\n",
    "In this exercise, you will apply unsupervised segmentation to the same image, before it's passed to a face detection machine learning model.  \n",
    "\n",
    "So you will reduce this image from 265Ã—191=50,615 pixels down to 400 regions.  \n",
    "\n",
    "Already preloaded as face_image.  \n",
    "The show_image() function has been preloaded for you as well.\n",
    "\n",
    "### Instructions\n",
    "Import the slic() function from the segmentation module.  \n",
    "Import the label2rgb() function from the color module.  \n",
    "Obtain the segmentation with 400 regions using slic().  \n",
    "Put segments on top of original image to compare with label2rgb()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the slic function from segmentation module\n",
    "from skimage.segmentation import slic\n",
    "\n",
    "# Import the label2rgb function from color module\n",
    "from skimage.color import label2rgb\n",
    "\n",
    "# Obtain the segmentation with 400 regions\n",
    "segments = slic(face_image, n_segments=400)\n",
    "\n",
    "# Put segments on top of original image to compare\n",
    "segmented_image = label2rgb(segments, face_image, kind='avg')\n",
    "\n",
    "# Show the segmented image\n",
    "show_image(segmented_image, \"Segmented image, 400 superpixels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contouring shapes\n",
    "In this exercise we'll find the contour of a horse. \n",
    "\n",
    "For that we will make use of a binarized image provided by scikit-image in its data module. Binarized images are easier to process when finding contours with this algorithm. Remember that contour finding only supports 2D image arrays.    \n",
    "\n",
    "Once the contour is detected, we will display it together with the original image. That way we can check if our analysis was correct!     \n",
    "\n",
    "show_image_contour(image, contours) is a preloaded function that displays the image with all contours found using Matplotlib.     \n",
    "\n",
    "Shape of a horse in black and white    \n",
    "Remember you can use the find_contours() function from the measure module, by passing the thresholded image and a constant value.\n",
    "\n",
    "### Instructions\n",
    "Import the data and the module needed for contouring detection.     \n",
    "Obtain the horse image shown in the context area.  \n",
    "Find the contours of the horse image using a constant level value of 0.8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the modules\n",
    "from skimage import data, measure\n",
    "\n",
    "# Obtain the horse image\n",
    "horse_image = data.horse()\n",
    "\n",
    "# Find the contours with a constant level value of 0.8\n",
    "contours = measure.find_contours(horse_image, .8 )\n",
    "\n",
    "# Shows the image with contours found\n",
    "show_image_contour(horse_image, contours)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find contours of an image that is not binary\n",
    "Let's work a bit more on how to prepare an image to be able to find its contours and extract information from it.  \n",
    "\n",
    "We'll process an image of two purple dices loaded as image_dices and determine what number was rolled for each dice.   \n",
    "\n",
    "In this case, the image is not grayscale or binary yet. This means we need to perform some image pre-processing steps before looking for the contours. First, we'll transform the image to a 2D array grayscale image and next apply thresholding. Finally, the contours are displayed together with the original image.  \n",
    "\n",
    "color, measure and filters modules are already imported so you can use the functions to find contours and apply thresholding.  \n",
    "\n",
    "We also import io module to load the image_dices from local memory, using imread. Read more here.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "Transform the image to grayscale using rgb2gray().  \n",
    "Obtain the optimal threshold value for the image and set it as thresh.  \n",
    "Apply thresholding to the image once you have the optimal threshold value thresh, using the corresponding operator.   \n",
    "Apply the corresponding function to obtain the contours and use a value level of 0.8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the image grayscale\n",
    "image_dices = color.rgb2gray(image_dices)\n",
    "\n",
    "# Obtain the optimal thresh value\n",
    "thresh = filters.threshold_otsu(image_dices)\n",
    "\n",
    "# Apply thresholding\n",
    "binary = image_dices > thresh\n",
    "\n",
    "# Find contours at a constant value of 0.8\n",
    "contours = measure.find_contours(binary, .8)\n",
    "\n",
    "# Show the image\n",
    "show_image_contour(image_dices, contours)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count the dots in a dice's image\n",
    "Now we have found the contours, we can extract information from it.   \n",
    "\n",
    "In the previous exercise, we prepared a purple dices image to find its contours:  \n",
    "\n",
    "3 images showing the steps to find contours   \n",
    "\n",
    "This time we'll determine what number was rolled for the dice, by counting the dots in the image.\n",
    "\n",
    "The contours found in the previous exercise are preloaded as contours.    \n",
    "\n",
    "Create a list with all contour's shapes as shape_contours. You can see all the contours shapes by calling shape_contours in the console, once you have created it.   \n",
    "\n",
    "Check that most of the contours aren't bigger in size than 50. If you count them, they are the exact number of dots in the image.    \n",
    "\n",
    "show_image_contour(image, contours) is a preloaded function that displays the image with all contours found using Matplotlib.\n",
    "\n",
    "### Instructions\n",
    "Make shape_contours be a list with all contour shapes of contours.     \n",
    "Set max_dots_shape to 50.    \n",
    "Set the shape condition of the contours to be the maximum shape size of the dots max_dots_shape.     \n",
    "Print the dice's number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list with the shape of each contour\n",
    "shape_contours = [cnt.shape[0] for cnt in contours]\n",
    "\n",
    "# Set 50 as the maximum size of the dots shape\n",
    "max_dots_shape = 50\n",
    "\n",
    "# Count dots in contours excluding bigger than dots size\n",
    "dots_contours = [cnt for cnt in contours if np.shape(cnt)[0] < 50]\n",
    "\n",
    "# Shows all contours found \n",
    "show_image_contour(binary, contours)\n",
    "\n",
    "# Print the dice's number\n",
    "print(\"Dice's dots number: {}. \".format(len(dots_contours)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
