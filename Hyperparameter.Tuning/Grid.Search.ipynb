{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Grid Search functions\n",
    "In data science it is a great idea to try building algorithms, models and processes 'from scratch' so you can really understand what is happening at a deeper level. Of course there are great packages and libraries for this work (and we will get to that very soon!) but building from scratch will give you a great edge in your data science work.  \n",
    "\n",
    "In this exercise, you will create a function to take in 2 hyperparameters, build models and return results. You will use this function in a future exercise.  \n",
    "\n",
    "You will have available the X_train, X_test, y_train and y_test datasets available.\n",
    "\n",
    "### Instructions\n",
    "Build a function that takes two parameters called learn_rate and max_depth for the learning rate and maximum depth.  \n",
    "Add capability in the function to build a GBM model and fit it to the data with the input hyperparameters.  \n",
    "Have the function return the results of that model and the chosen hyperparameters (learn_rate and max_depth).\n",
    "Take Hint (-30 XP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the function\n",
    "def gbm_grid_search(learn_rate, max_depth):\n",
    "\n",
    "\t# Create the model\n",
    "    model = GradientBoostingClassifier(learning_rate=learn_rate, max_depth=max_depth)\n",
    "    \n",
    "    # Use the model to make predictions\n",
    "    predictions = model.fit(X_train, y_train).predict(X_test)\n",
    "    \n",
    "    # Return the hyperparameters and score\n",
    "    return([learn_rate, max_depth, accuracy_score(y_test, predictions)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iteratively tune multiple hyperparameters\n",
    "In this exercise, you will build on the function you previously created to take in 2 hyperparameters, build a model and return the results. You will now use that to loop through some values and then extend this function and loop with another hyperparameter.   \n",
    "\n",
    "The function gbm_grid_search(learn_rate, max_depth) is available in this exercise.   \n",
    "\n",
    "If you need to remind yourself of the function you can run the function print_func() that has been created for you\n",
    "\n",
    "### Instructions \n",
    "Write a for-loop to test the values (0.01, 0.1, 0.5) for the learning_rate and (2, 4, 6) for the max_depth using the function you created gbm_grid_search and print the results.  \n",
    "Extend the gbm_grid_search function to include the hyperparameter subsample. Name this new function gbm_grid_search_extended.  \n",
    "Extend your loop to call gbm_grid_search (available in your console), then test the values [0.4 , 0.6] for the subsample hyperparameter and print the results. max_depth_list & learn_rate_list are available in your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the relevant lists\n",
    "results_list = []\n",
    "learn_rate_list = [.01,.1,.5]\n",
    "max_depth_list = [2,4,6]\n",
    "\n",
    "# Create the for loop\n",
    "for learn_rate in learn_rate_list:\n",
    "    for max_depth in max_depth_list:\n",
    "        results_list.append(gbm_grid_search(learn_rate,max_depth))\n",
    "\n",
    "# Print the results\n",
    "print(results_list)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV with Scikit Learn\n",
    "The GridSearchCV module from Scikit Learn provides many useful features to assist with efficiently undertaking a grid search. You will now put your learning into practice by creating a GridSearchCV object with certain parameters.  \n",
    "The desired options are:  \n",
    "A Random Forest Estimator, with the split criterion as 'entropy'  \n",
    "5-fold cross validation  \n",
    "The hyperparameters max_depth (2, 4, 8, 15) and max_features ('auto' vs 'sqrt')  \n",
    "Use roc_auc to score the models  \n",
    "Use 4 cores for processing in parallel  \n",
    "Ensure you refit the best model and return training scores  \n",
    "You will have available X_train, X_test, y_train & y_test datasets.  \n",
    "### Instructions\n",
    "Create a Random Forest estimator as specified in the context above.  \n",
    "Create a parameter grid as specified in the context above.  \n",
    "Create a GridSearchCV object as outlined in the context above, using the two elements created in the previous two instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Random Forest Classifier with specified criterion\n",
    "rf_class = RandomForestClassifier(criterion='entropy')\n",
    "\n",
    "# Create the parameter grid\n",
    "param_grid = {'max_depth': [2,4,8,15], 'max_features': ['auto', 'sqrt']} \n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_rf_class = GridSearchCV(\n",
    "    estimator=rf_class,\n",
    "    param_grid=param_grid,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=4,\n",
    "    cv=5,\n",
    "    refit=True, return_train_score=True)\n",
    "print(grid_rf_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the grid search results\n",
    "You will now explore the cv_results_ property of the GridSearchCV object defined in the video. This is a dictionary that we can read into a pandas DataFrame and contains a lot of useful information about the grid search we just undertook.   \n",
    "A reminder of the different column types in this property:  \n",
    "time_ columns  \n",
    "param_ columns (one for each hyperparameter) and the singular params column (with all hyperparameter settings)  \n",
    "a train_score column for each cv fold including the mean_train_score and std_train_score columns  \n",
    "a test_score column for each cv fold including the mean_test_score and std_test_score columns  \n",
    "a rank_test_score column with a number from 1 to n (number of iterations) ranking the rows based on their mean_test_score  \n",
    "### Instructions\n",
    "Read the cv_results_ property of the grid_rf_class GridSearchCV object into a data frame & print the whole thing out to inspect.  \n",
    "Extract & print the singular column containing a dictionary of all hyperparameters used in each iteration of the grid search.  \n",
    "Extract & print the row that had the best mean test score by indexing using the rank_test_score column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the cv_results property into a dataframe & print it out\n",
    "cv_results_df = pd.DataFrame(grid_rf_class.cv_results_)\n",
    "print(cv_results_df)\n",
    "\n",
    "# Extract and print the column with a dictionary of hyperparameters used\n",
    "column = cv_results_df.loc[:, ['params']]\n",
    "print(column)\n",
    "\n",
    "# Extract and print the row that had the best mean test score\n",
    "best_row = cv_results_df[cv_results_df['rank_test_score'] == 1 ]\n",
    "print(best_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing the best results\n",
    "At the end of the day, we primarily care about the best performing 'square' in a grid search. Luckily Scikit Learn's gridSearchCv objects have a number of parameters that provide key information on just the best square (or row in cv_results_).\n",
    "\n",
    "Three properties you will explore are:\n",
    "\n",
    "best_score_ – The score (here ROC_AUC) from the best-performing square.   \n",
    "best_index_ – The index of the row in cv_results_ containing information on the best-performing square.  \n",
    "best_params_ – A dictionary of the parameters that gave the best score, for example 'max_depth': 10  \n",
    "The grid search object grid_rf_class is available.  \n",
    "\n",
    "A dataframe (cv_results_df) has been created from the cv_results_ for you on line 6. This will help you index into the results.\n",
    "\n",
    "### Instructions\n",
    "Extract and print out the ROC_AUC score from the best performing square in grid_rf_class.\n",
    "Create a variable from the best-performing row by indexing into cv_results_df.\n",
    "Create a variable, best_n_estimators by extracting the n_estimators parameter from the best-performing square in grid_rf_class and print it out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the best results\n",
    "While it is interesting to analyze the results of our grid search, our final goal is practical in nature; we want to make predictions on our test set using our estimator object.\n",
    "\n",
    "We can access this object through the best_estimator_ property of our grid search object.\n",
    "\n",
    "In this exercise we will take a look inside the best_estimator_ property and then use this to make predictions on our test set for credit card defaults and generate a variety of scores. Remember to use predict_proba rather than predict since we need probability values rather than class labels for our roc_auc score. We use a slice [:,1] to get probabilities of the positive class.\n",
    "\n",
    "You have available the X_test and y_test datasets to use and the grid_rf_class object from previous exercises.\n",
    "\n",
    "### Instructions\n",
    "Check the type of the best_estimator_ property.  \n",
    "Use the best_estimator_ property to make predictions on our test set.  \n",
    "Generate a confusion matrix and ROC_AUC score from our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See what type of object the best_estimator_ property is\n",
    "print(type(grid_rf_class.best_estimator_))\n",
    "\n",
    "# Create an array of predictions directly using the best_estimator_ property\n",
    "predictions = grid_rf_class.best_estimator_.predict(X_test)\n",
    "\n",
    "# Take a look to confirm it worked, this should be an array of 1's and 0's\n",
    "print(predictions[0:5])\n",
    "\n",
    "# Now create a confusion matrix \n",
    "print(\"Confusion Matrix \\n\", confusion_matrix(y_test, predictions))\n",
    "\n",
    "# Get the ROC-AUC score\n",
    "predictions_proba = grid_rf_class.best_estimator_.predict_proba(X_test)[:,1]\n",
    "print(\"ROC-AUC Score \\n\", roc_auc_score(y_test, predictions_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
